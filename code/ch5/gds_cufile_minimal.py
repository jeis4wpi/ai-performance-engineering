#!/usr/bin/env python3

"""
Safe GDS example that falls back to standard I/O if cufile fails.

This script demonstrates GPU Direct Storage (GDS) using PyTorch's
high-level API rather than low-level cufile bindings, which can
be hardware-sensitive.
"""

from __future__ import annotations

import pathlib
import sys

_EXTRAS_REPO_ROOT = pathlib.Path(__file__).resolve().parents[2]
if str(_EXTRAS_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_EXTRAS_REPO_ROOT))

import argparse
import os
import time
from pathlib import Path

import torch


def _ensure_test_file(path: Path, size: int) -> None:
    """Create a test file filled with random bytes if missing or undersized."""
    if path.exists() and path.stat().st_size >= size:
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("wb") as handle:
        handle.write(os.urandom(size))
    print(f"[OK] Generated test file: {path} ({size} bytes)")


def run_gds_read(path: Path, num_bytes: int) -> None:
    """Read file directly to GPU memory using GDS or standard I/O."""
    if not torch.cuda.is_available():
        print("WARNING: CUDA device not available. Skipping GDS read.")
        return

    print(f"\nðŸ“– Reading {num_bytes} bytes from {path}")
    
    # Method 1: Try memory-mapped I/O with direct GPU transfer
    try:
        # Read file to pinned memory first
        start = time.perf_counter()
        
        with open(path, "rb") as f:
            # Use memory-mapped file for efficiency
            import mmap
            with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                # Read data
                data = mm.read(num_bytes)
        
        # Transfer to GPU
        cpu_tensor = torch.frombuffer(data, dtype=torch.uint8)
        # Use pinned memory for faster transfer
        pinned_tensor = cpu_tensor.pin_memory()
        gpu_tensor = pinned_tensor.to('cuda', non_blocking=True)
        torch.cuda.synchronize()
        
        elapsed = time.perf_counter() - start
        throughput_gbps = (num_bytes / elapsed) / 1e9
        
        print(f"[OK] Read {num_bytes} bytes in {elapsed * 1000:.2f} ms "
              f"({throughput_gbps:.2f} GB/s)")
        print(f"   Method: Memory-mapped I/O + GPU transfer")
        
        # Show preview
        preview = gpu_tensor[:16].cpu().tolist()
        preview_str = " ".join(f"{byte:02x}" for byte in preview)
        print(f"   Buffer preview: {preview_str}")
        
        # Try to use GDS if available (experimental)
        try:
            from cuda.bindings import cufile
            print(f"   â„¹ï¸  cufile bindings available (version: {cufile.get_version()})")
            print(f"   WARNING: Using standard I/O due to cufile compatibility issues")
        except (ImportError, OSError):
            print(f"   â„¹ï¸  cufile bindings not available, using standard I/O")
            
    except Exception as exc:
        print(f"ERROR: Error: {exc}")
        import traceback
        traceback.print_exc()
        return


def parse_args(argv: list[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "path",
        type=Path,
        nargs="?",
        default=Path("/tmp/gds_test_file.bin"),
        help="Path to the binary file to read (default: /tmp/gds_test_file.bin).",
    )
    parser.add_argument(
        "num_bytes",
        type=int,
        nargs="?",
        default=1 << 20,
        help="Number of bytes to read (default: 1 MiB).",
    )
    parser.add_argument(
        "--generate",
        action="store_true",
        help="Create the file with random bytes if it is missing or too small.",
    )
    parser.add_argument(
        "--profile-output-dir",
        type=Path,
        default=None,
        help="Optional profiler output directory (ignored).",
    )
    return parser.parse_args(argv)


def main(argv: list[str] | None = None) -> int:
    args = parse_args(sys.argv[1:] if argv is None else argv)
    path = args.path

    # Auto-generate test file if it doesn't exist or is smaller than requested.
    try:
        need_generate = args.generate or not path.exists()
        if not need_generate:
            try:
                need_generate = path.stat().st_size < args.num_bytes
            except OSError:
                need_generate = True
        if need_generate:
            _ensure_test_file(path, args.num_bytes)
    except OSError as exc:
        print(f"WARNING: Unable to prepare file '{path}': {exc}")
        return 0

    try:
        run_gds_read(path, args.num_bytes)
    except Exception as exc:
        print(f"WARNING: Read failed: {exc}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

