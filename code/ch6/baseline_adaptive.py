"""baseline_adaptive.py - Baseline without adaptive optimization. Demonstrates operations with static configuration (no runtime adaptation). Implements Benchmark protocol for harness integration. """ from __future__ import annotations import sys from pathlib import Path repo_root = Path(__file__).parent.parent if str(repo_root) not in sys.path: sys.path.insert(0, str(repo_root)) import torch from typing import Optional from common.python.benchmark_harness import ( Benchmark, BenchmarkConfig, ) def resolve_device() -> torch.device: """Return CUDA device if available.""" if not torch.cuda.is_available(): raise RuntimeError("CUDA required for ch6") return torch.device("cuda") class BaselineAdaptiveBenchmark(Benchmark): """Baseline: Static configuration (no adaptive optimization).""" def __init__(self): self.device = resolve_device() self.input = None self.output = None self.N = 1_000_000 def setup(self) -> None: """Setup: Initialize with static configuration.""" torch.manual_seed(42) # Baseline: Static configuration # Adaptive optimization adjusts parameters at runtime based on workload # This baseline uses fixed configuration that doesn't adapt self.input = torch.randn(self.N, device=self.device, dtype=torch.float32) self.output = torch.empty(self.N, device=self.device, dtype=torch.float32) torch.cuda.synchronize() def benchmark_fn(self) -> None: """Benchmark: Static configuration operations.""" torch.cuda.nvtx.range_push("baseline_adaptive") try: # Baseline: Static configuration (no adaptation) # Adaptive optimization adjusts kernel parameters at runtime # This baseline does not adapt to workload characteristics self.output = self.input * 2.0 + 1.0 # Static configuration may not be optimal for varying workloads finally: torch.cuda.nvtx.range_pop() def teardown(self) -> None: """Teardown: Clean up resources.""" self.input = None self.output = None torch.cuda.empty_cache() def get_config(self) -> BenchmarkConfig: """Return benchmark configuration.""" return BenchmarkConfig( iterations=100, warmup=10, ) def validate_result(self) -> Optional[str]: """Validate benchmark result.""" if self.output is None: return "Output tensor not initialized" return None def get_benchmark() -> Benchmark: """Factory function for benchmark discovery.""" return BaselineAdaptiveBenchmark() if __name__ == '__main__': from common.python.benchmark_harness import BenchmarkHarness, BenchmarkMode benchmark = get_benchmark() harness = BenchmarkHarness( mode=BenchmarkMode.CUSTOM, config=benchmark.get_config() ) result = harness.benchmark(benchmark) print(f"\nBaseline Adaptive (Static): {result.mean_ms:.3f} ms") print(" Note: Uses static configuration, does not adapt to workload") 